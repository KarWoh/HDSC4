{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/planet-understanding-the-amazon-from-space'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-21T21:36:56.297765Z","iopub.execute_input":"2023-03-21T21:36:56.298196Z","iopub.status.idle":"2023-03-21T21:36:56.309750Z","shell.execute_reply.started":"2023-03-21T21:36:56.298161Z","shell.execute_reply":"2023-03-21T21:36:56.308587Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/input/planet-understanding-the-amazon-from-space/Kaggle-planet-train-tif.torrent\n/kaggle/input/planet-understanding-the-amazon-from-space/Kaggle-planet-test-tif.torrent\n/kaggle/input/planet-understanding-the-amazon-from-space/test_v2_file_mapping.csv/test_v2_file_mapping.csv\n/kaggle/input/planet-understanding-the-amazon-from-space/train_v2.csv/train_v2.csv\n/kaggle/input/planet-understanding-the-amazon-from-space/sample_submission_v2.csv/sample_submission_v2.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Libraries for Data Visualisation\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom keras import optimizers\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input , Dense , Dropout , Flatten,\\\nConv2D,MaxPooling2D , BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:36:58.994284Z","iopub.execute_input":"2023-03-21T21:36:58.994701Z","iopub.status.idle":"2023-03-21T21:36:59.002856Z","shell.execute_reply.started":"2023-03-21T21:36:58.994662Z","shell.execute_reply":"2023-03-21T21:36:59.001619Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"path = \"../input/planets-dataset/\"\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:38:27.154809Z","iopub.execute_input":"2023-03-21T21:38:27.155260Z","iopub.status.idle":"2023-03-21T21:38:27.167347Z","shell.execute_reply.started":"2023-03-21T21:38:27.155221Z","shell.execute_reply":"2023-03-21T21:38:27.166369Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['planet', 'test-jpg-additional']"},"metadata":{}}]},{"cell_type":"code","source":"train_label = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/train_classes.csv\")\ntrain_label.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:38:39.541418Z","iopub.execute_input":"2023-03-21T21:38:39.541808Z","iopub.status.idle":"2023-03-21T21:38:39.627743Z","shell.execute_reply.started":"2023-03-21T21:38:39.541772Z","shell.execute_reply":"2023-03-21T21:38:39.626455Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = set()\ndef splitting_tags(tags):\n    '''\n    Takes in tags column, splits the tags and store as a set\n    '''\n    [labels.add(tag) for tag in tags.split()]\n    \n# Create a copy of train_label\ntrain = train_label.copy()\ntrain['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:38:47.177027Z","iopub.execute_input":"2023-03-21T21:38:47.177476Z","iopub.status.idle":"2023-03-21T21:38:47.242868Z","shell.execute_reply.started":"2023-03-21T21:38:47.177439Z","shell.execute_reply":"2023-03-21T21:38:47.241480Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['clear', 'blooming', 'conventional_mine', 'cultivation', 'selective_logging', 'slash_burn', 'bare_ground', 'road', 'habitation', 'cloudy', 'blow_down', 'partly_cloudy', 'water', 'primary', 'haze', 'agriculture', 'artisinal_mine']\n","output_type":"stream"}]},{"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes \n\nfor tag in labels:\n    train[tag] = train['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n## adding .jpg extension to the column image_name so as to have same name format as the image files\ntrain['image_name'] = train['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:38:52.827546Z","iopub.execute_input":"2023-03-21T21:38:52.828002Z","iopub.status.idle":"2023-03-21T21:38:53.347678Z","shell.execute_reply.started":"2023-03-21T21:38:52.827964Z","shell.execute_reply":"2023-03-21T21:38:53.346543Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"    image_name                                       tags  clear  blooming  \\\n0  train_0.jpg                               haze primary      0         0   \n1  train_1.jpg            agriculture clear primary water      1         0   \n2  train_2.jpg                              clear primary      1         0   \n3  train_3.jpg                              clear primary      1         0   \n4  train_4.jpg  agriculture clear habitation primary road      1         0   \n\n   conventional_mine  cultivation  selective_logging  slash_burn  bare_ground  \\\n0                  0            0                  0           0            0   \n1                  0            0                  0           0            0   \n2                  0            0                  0           0            0   \n3                  0            0                  0           0            0   \n4                  0            0                  0           0            0   \n\n   road  habitation  cloudy  blow_down  partly_cloudy  water  primary  haze  \\\n0     0           0       0          0              0      0        1     1   \n1     0           0       0          0              0      1        1     0   \n2     0           0       0          0              0      0        1     0   \n3     0           0       0          0              0      0        1     0   \n4     1           1       0          0              0      0        1     0   \n\n   agriculture  artisinal_mine  \n0            0               0  \n1            1               0  \n2            0               0  \n3            0               0  \n4            1               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n      <th>clear</th>\n      <th>blooming</th>\n      <th>conventional_mine</th>\n      <th>cultivation</th>\n      <th>selective_logging</th>\n      <th>slash_burn</th>\n      <th>bare_ground</th>\n      <th>road</th>\n      <th>habitation</th>\n      <th>cloudy</th>\n      <th>blow_down</th>\n      <th>partly_cloudy</th>\n      <th>water</th>\n      <th>primary</th>\n      <th>haze</th>\n      <th>agriculture</th>\n      <th>artisinal_mine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0.jpg</td>\n      <td>haze primary</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1.jpg</td>\n      <td>agriculture clear primary water</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4.jpg</td>\n      <td>agriculture clear habitation primary road</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#importing libraries for training\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:00.246245Z","iopub.execute_input":"2023-03-21T21:39:00.246666Z","iopub.status.idle":"2023-03-21T21:39:00.253505Z","shell.execute_reply.started":"2023-03-21T21:39:00.246626Z","shell.execute_reply":"2023-03-21T21:39:00.252218Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Defining the columns,i.e the labels that were newly added to the train_classes via hot encoding.\ncolumns = list(train.columns[2:])","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:06.329673Z","iopub.execute_input":"2023-03-21T21:39:06.330085Z","iopub.status.idle":"2023-03-21T21:39:06.335415Z","shell.execute_reply.started":"2023-03-21T21:39:06.330048Z","shell.execute_reply":"2023-03-21T21:39:06.334230Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"columns","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:11.043392Z","iopub.execute_input":"2023-03-21T21:39:11.044354Z","iopub.status.idle":"2023-03-21T21:39:11.054288Z","shell.execute_reply.started":"2023-03-21T21:39:11.044305Z","shell.execute_reply":"2023-03-21T21:39:11.052982Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['clear',\n 'blooming',\n 'conventional_mine',\n 'cultivation',\n 'selective_logging',\n 'slash_burn',\n 'bare_ground',\n 'road',\n 'habitation',\n 'cloudy',\n 'blow_down',\n 'partly_cloudy',\n 'water',\n 'primary',\n 'haze',\n 'agriculture',\n 'artisinal_mine']"},"metadata":{}}]},{"cell_type":"code","source":"def fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n    '''\n    Set y_true and y_pred\n\n    Args:\n        y_true: correct target values\n        Y_pred: predicted values returned by the classifer\n        beta = 2\n        epsilon= 1e-4\n        \n    Returns:\n        fbeta score\n    '''\n    \n    beta_squared = beta**2\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n    return fb","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:19.550216Z","iopub.execute_input":"2023-03-21T21:39:19.550715Z","iopub.status.idle":"2023-03-21T21:39:19.561507Z","shell.execute_reply.started":"2023-03-21T21:39:19.550667Z","shell.execute_reply":"2023-03-21T21:39:19.560198Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n    '''\n    Retuns accuracy value for multi_label classification\n    \n    Set y_true and y_pred\n\n    Args:\n        y_true: correct target values\n        Y_pred: predicted values returned by the classifer\n        epsilon= 1e-4\n        \n    Returns:\n        Accuracy score\n    '''\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n        \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32)\n                       * tf.cast(tf.logical_not(y_pred), tf.float32), axis = 1)\n    \n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:26.036586Z","iopub.execute_input":"2023-03-21T21:39:26.037308Z","iopub.status.idle":"2023-03-21T21:39:26.046399Z","shell.execute_reply.started":"2023-03-21T21:39:26.037265Z","shell.execute_reply":"2023-03-21T21:39:26.045021Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#defining our model\ndef build_model():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n\n    opt = Adam(lr=1e-4)\n    \n    # We need binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n    model.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=[multi_label_acc, fbeta])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:32.946417Z","iopub.execute_input":"2023-03-21T21:39:32.946860Z","iopub.status.idle":"2023-03-21T21:39:32.961344Z","shell.execute_reply.started":"2023-03-21T21:39:32.946820Z","shell.execute_reply":"2023-03-21T21:39:32.960093Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\nsave_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', \n                                        monitor = 'val_fbeta',\n                                        mode = 'max',\n                                        save_best_only = True,\n                                        save_weights_only = True)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:38.884547Z","iopub.execute_input":"2023-03-21T21:39:38.885014Z","iopub.status.idle":"2023-03-21T21:39:38.890823Z","shell.execute_reply.started":"2023-03-21T21:39:38.884971Z","shell.execute_reply":"2023-03-21T21:39:38.889487Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#initializing imagedatagenerator with a validation split of 0.2\ntrain_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n\n#generating train data generator which is 80% of the train dataset\n#note that a generator contains both features and target of the data\ntrain_generator = train_image_gen.flow_from_dataframe(dataframe=train,\n                                                directory =\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))\n\n#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\nval_generator = train_image_gen.flow_from_dataframe(dataframe=train,\n                                                directory =\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:39:45.528398Z","iopub.execute_input":"2023-03-21T21:39:45.528803Z","iopub.status.idle":"2023-03-21T21:40:55.829973Z","shell.execute_reply.started":"2023-03-21T21:39:45.528769Z","shell.execute_reply":"2023-03-21T21:40:55.829024Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 32384 validated image filenames.\nFound 8095 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n#setting up step size for training and validation image data\nstep_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\nstep_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:41:31.456924Z","iopub.execute_input":"2023-03-21T21:41:31.457332Z","iopub.status.idle":"2023-03-21T21:41:31.462773Z","shell.execute_reply.started":"2023-03-21T21:41:31.457296Z","shell.execute_reply":"2023-03-21T21:41:31.461885Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#initialize the model\nmodel1 = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:41:38.719329Z","iopub.execute_input":"2023-03-21T21:41:38.719741Z","iopub.status.idle":"2023-03-21T21:41:39.402040Z","shell.execute_reply.started":"2023-03-21T21:41:38.719707Z","shell.execute_reply":"2023-03-21T21:41:39.400972Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Preview the model architecture\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:41:43.890634Z","iopub.execute_input":"2023-03-21T21:41:43.891118Z","iopub.status.idle":"2023-03-21T21:41:43.952269Z","shell.execute_reply.started":"2023-03-21T21:41:43.891075Z","shell.execute_reply":"2023-03-21T21:41:43.951075Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n batch_normalization (BatchN  (None, 128, 128, 3)      12        \n ormalization)                                                   \n                                                                 \n conv2d (Conv2D)             (None, 128, 128, 32)      896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 63, 63, 32)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n                                                                 \n conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n                                                                 \n conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n                                                                 \n conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n 2D)                                                             \n                                                                 \n dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n                                                                 \n conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n                                                                 \n conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n 2D)                                                             \n                                                                 \n dropout_3 (Dropout)         (None, 6, 6, 256)         0         \n                                                                 \n flatten (Flatten)           (None, 9216)              0         \n                                                                 \n dense (Dense)               (None, 512)               4719104   \n                                                                 \n dropout_4 (Dropout)         (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 17)                8721      \n                                                                 \n=================================================================\nTotal params: 5,900,093\nTrainable params: 5,900,087\nNon-trainable params: 6\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#fitting our model using the parameters already defined \nmodel1.fit(x = train_generator, \n           steps_per_epoch = step_train_size, \n           validation_data = val_generator, \n           validation_steps = step_val_size,epochs = 15, \n           callbacks=[save_best_check_point])","metadata":{"execution":{"iopub.status.busy":"2023-03-21T21:41:53.845066Z","iopub.execute_input":"2023-03-21T21:41:53.845486Z","iopub.status.idle":"2023-03-21T22:47:36.887749Z","shell.execute_reply.started":"2023-03-21T21:41:53.845445Z","shell.execute_reply":"2023-03-21T22:47:36.885595Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/15\n2024/2024 [==============================] - 2419s 1s/step - loss: 0.2102 - multi_label_acc: 0.9179 - fbeta: 0.6922 - val_loss: 0.1734 - val_multi_label_acc: 0.9305 - val_fbeta: 0.7507\nEpoch 2/15\n1358/2024 [===================>..........] - ETA: 12:26 - loss: 0.1755 - multi_label_acc: 0.9312 - fbeta: 0.7570","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2554474375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_val_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m            callbacks=[save_best_check_point])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#initializing a second model to make predictions\nmodel2 = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:47:43.353687Z","iopub.execute_input":"2023-03-21T22:47:43.354659Z","iopub.status.idle":"2023-03-21T22:47:43.580627Z","shell.execute_reply.started":"2023-03-21T22:47:43.354607Z","shell.execute_reply":"2023-03-21T22:47:43.579565Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#loading in the weights of the trained model\nmodel2.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:47:45.977306Z","iopub.execute_input":"2023-03-21T22:47:45.978129Z","iopub.status.idle":"2023-03-21T22:47:46.038258Z","shell.execute_reply.started":"2023-03-21T22:47:45.978071Z","shell.execute_reply":"2023-03-21T22:47:46.036963Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"##adding .jpg extension to image name in the sample submission file\nsample_submission = pd.read_csv('/kaggle/input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:47:51.518972Z","iopub.execute_input":"2023-03-21T22:47:51.519400Z","iopub.status.idle":"2023-03-21T22:47:51.647291Z","shell.execute_reply.started":"2023-03-21T22:47:51.519361Z","shell.execute_reply":"2023-03-21T22:47:51.645828Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   image_name                                  tags\n0  test_0.jpg  primary clear agriculture road water\n1  test_1.jpg  primary clear agriculture road water\n2  test_2.jpg  primary clear agriculture road water\n3  test_3.jpg  primary clear agriculture road water\n4  test_4.jpg  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Divide the sample submission file into two splits,\n# first test_df which contains the first 40669 images \ntest_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:47:58.995448Z","iopub.execute_input":"2023-03-21T22:47:58.995852Z","iopub.status.idle":"2023-03-21T22:47:59.014666Z","shell.execute_reply.started":"2023-03-21T22:47:58.995819Z","shell.execute_reply":"2023-03-21T22:47:59.013516Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   image_name\n0  test_0.jpg\n1  test_1.jpg\n2  test_2.jpg\n3  test_3.jpg\n4  test_4.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#initialize imagedatagenerator for the test images and also rescaling\ntest_image_gen = ImageDataGenerator(rescale = 1/255)\n\n#creating a generator for the images found in the first test image files\ntest_generator = test_image_gen.flow_from_dataframe(dataframe=test_df, \n                                                directory=\"/kaggle/input/planets-dataset/planet/planet/test-jpg\", \n                                                x_col=\"image_name\", \n                                                y_col=None, \n                                                batch_size=16, \n                                                shuffle=False, \n                                                class_mode=None, \n                                                target_size=(128,128))\n\nstep_test_size = int(np.ceil(test_generator.samples/test_generator.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:48:07.087728Z","iopub.execute_input":"2023-03-21T22:48:07.088174Z","iopub.status.idle":"2023-03-21T22:49:19.769846Z","shell.execute_reply.started":"2023-03-21T22:48:07.088132Z","shell.execute_reply":"2023-03-21T22:49:19.768922Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Found 40669 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#first, we reset the test generator to avoid shuffling of index as we want it to be orderly\ntest_generator.reset()\npred = model2.predict(test_generator, steps = step_test_size, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T22:49:24.094214Z","iopub.execute_input":"2023-03-21T22:49:24.095125Z","iopub.status.idle":"2023-03-21T23:00:46.308287Z","shell.execute_reply.started":"2023-03-21T22:49:24.095081Z","shell.execute_reply":"2023-03-21T23:00:46.307028Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"2542/2542 [==============================] - 681s 268ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names = test_generator.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5 \npred_tags = pd.DataFrame(pred)\npred_tags = pred_tags.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this \nresult1 = pd.DataFrame({'image_name': file_names, 'tags': pred_tags})\nresult1.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:00:48.442021Z","iopub.execute_input":"2023-03-21T23:00:48.442421Z","iopub.status.idle":"2023-03-21T23:00:57.086080Z","shell.execute_reply.started":"2023-03-21T23:00:48.442388Z","shell.execute_reply":"2023-03-21T23:00:57.084759Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          clear primary\n1  test_1.jpg          clear primary\n2  test_2.jpg  partly_cloudy primary\n3  test_3.jpg          clear primary\n4  test_4.jpg  partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#additional test dataset\nadd_test_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\nadd_test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:01:08.981166Z","iopub.execute_input":"2023-03-21T23:01:08.981568Z","iopub.status.idle":"2023-03-21T23:01:08.997223Z","shell.execute_reply.started":"2023-03-21T23:01:08.981533Z","shell.execute_reply":"2023-03-21T23:01:08.995981Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"      image_name\n0     file_0.jpg\n1     file_1.jpg\n2    file_10.jpg\n3   file_100.jpg\n4  file_1000.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#creating a generator for the additional test image files\nadd_test_generator = test_image_gen.flow_from_dataframe(dataframe = add_test_df, \n                                                    directory =\"/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n                                                    x_col=\"image_name\", \n                                                    y_col=None, \n                                                    batch_size=16, \n                                                    shuffle=False, \n                                                    class_mode=None, \n                                                    target_size=(128,128))\n\n\nstep_test_size2 = int(np.ceil(add_test_generator.samples/add_test_generator.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:01:17.125643Z","iopub.execute_input":"2023-03-21T23:01:17.126095Z","iopub.status.idle":"2023-03-21T23:01:52.298239Z","shell.execute_reply.started":"2023-03-21T23:01:17.126039Z","shell.execute_reply":"2023-03-21T23:01:52.296773Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Found 20522 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#we reset the generator to avoid shuffling, then make prediction on the generator\nadd_test_generator.reset()\nadd_pred = model2.predict(add_test_generator, steps = step_test_size2, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:01:58.695469Z","iopub.execute_input":"2023-03-21T23:01:58.695870Z","iopub.status.idle":"2023-03-21T23:08:20.780788Z","shell.execute_reply.started":"2023-03-21T23:01:58.695833Z","shell.execute_reply":"2023-03-21T23:08:20.779871Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1283/1283 [==============================] - 346s 270ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names = add_test_generator.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5\nadd_pred_tags = pd.DataFrame(add_pred)\nadd_pred_tags = add_pred_tags.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this\nresult2 = pd.DataFrame({'image_name': file_names, 'tags': add_pred_tags})\nresult2.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:08:24.588291Z","iopub.execute_input":"2023-03-21T23:08:24.589177Z","iopub.status.idle":"2023-03-21T23:08:28.953887Z","shell.execute_reply.started":"2023-03-21T23:08:24.589132Z","shell.execute_reply":"2023-03-21T23:08:28.952698Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"      image_name                         tags\n0     file_0.jpg                 clearprimary\n1     file_1.jpg  clearroadprimaryagriculture\n2    file_10.jpg                      primary\n3   file_100.jpg                 clearprimary\n4  file_1000.jpg                 clearprimary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n      <td>clearprimary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n      <td>clearroadprimaryagriculture</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n      <td>primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n      <td>clearprimary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n      <td>clearprimary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#for the final result of the predicted tags for the test images,\n# we need to concat the first and second results in \n#that order to avoid shuffling the index\nlast_result = pd.concat([result1, result2])\n\nlast_result = last_result.reset_index().drop('index', axis =1)\n\nprint(last_result.shape)\n#print the final result\nlast_result.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:08:40.720598Z","iopub.execute_input":"2023-03-21T23:08:40.721163Z","iopub.status.idle":"2023-03-21T23:08:40.747435Z","shell.execute_reply.started":"2023-03-21T23:08:40.721099Z","shell.execute_reply":"2023-03-21T23:08:40.746002Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"(61191, 2)\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          clear primary\n1  test_1.jpg          clear primary\n2  test_2.jpg  partly_cloudy primary\n3  test_3.jpg          clear primary\n4  test_4.jpg  partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#we need to remove the .jpg extension from the image_name of the\n# last_result because from the sample submission the \n#extension was not there, we added it for easy manipulation of the data.\nlast_result['image_name'] = last_result['image_name'].apply(lambda x: x[:-4])\nlast_result.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:08:50.829176Z","iopub.execute_input":"2023-03-21T23:08:50.829567Z","iopub.status.idle":"2023-03-21T23:08:50.861297Z","shell.execute_reply.started":"2023-03-21T23:08:50.829531Z","shell.execute_reply":"2023-03-21T23:08:50.859818Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"  image_name                   tags\n0     test_0          clear primary\n1     test_1          clear primary\n2     test_2  partly_cloudy primary\n3     test_3          clear primary\n4     test_4  partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Finally, we save the result to a csv file using the .to_csv() \n# method and setting the index to false.\nlast_result.to_csv('submission1.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T23:09:13.436495Z","iopub.execute_input":"2023-03-21T23:09:13.436894Z","iopub.status.idle":"2023-03-21T23:09:13.532523Z","shell.execute_reply.started":"2023-03-21T23:09:13.436857Z","shell.execute_reply":"2023-03-21T23:09:13.531288Z"},"trusted":true},"execution_count":41,"outputs":[]}]}